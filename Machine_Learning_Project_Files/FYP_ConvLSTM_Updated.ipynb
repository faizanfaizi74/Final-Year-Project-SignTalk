{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07ZAtJ4wUOEI"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEWGQmw-gmmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda9ca70-c318-4fca-fc55-96d90e525057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import random\n",
        "import ssl\n",
        "import imageio\n",
        "from IPython import display\n",
        "from urllib import request\n",
        "import re\n",
        "import tempfile\n",
        "from keras import backend as K\n",
        "import sys\n",
        "import csv\n",
        "from collections import deque\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from google.colab import drive\n",
        "import gc\n",
        "\n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np # MATRIX OPERATIONS\n",
        "import pandas as pd # EFFICIENT DATA STRUCTURES\n",
        "import matplotlib.pyplot as plt # GRAPHING AND VISUALIZATIONS\n",
        "%matplotlib inline\n",
        "import math # MATHEMATICAL OPERATIONS\n",
        "import cv2 # IMAGE PROCESSING - OPENCV\n",
        "import os\n",
        "from glob import glob # FILE OPERATIONS\n",
        "import itertools\n",
        "\n",
        "# KERAS AND SKLEARN MODULES\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten,MaxPool2D\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten,  BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,CSVLogger, TensorBoard\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLy2VlgwdKRc"
      },
      "outputs": [],
      "source": [
        "seed_constant = 30\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d-IHs8QURbf"
      },
      "source": [
        "## Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abU8MJxzgxCv",
        "outputId": "f961ef6b-a36e-4c25-def7-59d89d043132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#importing google drive in google colab\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPzLM7h9l-ut"
      },
      "outputs": [],
      "source": [
        "DATASET_DIR = '/content/gdrive/MyDrive/sign_videos_sample_a_6'\n",
        "FOLDER_ROOT = '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6ftDhNkdrWV"
      },
      "outputs": [],
      "source": [
        "IMAGE_HEIGHT, IMAGE_WIDTH = 224, 224\n",
        "SEQUENCE_LENGTH = 20\n",
        "\n",
        "CLASSES_LIST = ['call_the_ambulance','i_am_a_student','i_can_not_speak', 'how_are_you', \"i_don't_understand\", 'extra_class'] # 5 a, \n",
        "\n",
        "# CLASSES_LIST = ['i_need_your_help', 'thank_you', 'what_is_the_time', 'what_is_your_name', 'yes'] #5 b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "kDTGPG61h30q",
        "outputId": "0e14f0fc-5f8f-4e33-a1f9-60089303b02b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  class                                               path\n",
              "0     0  /content/gdrive/MyDrive/sign_videos_sample_a_6...\n",
              "1     0  /content/gdrive/MyDrive/sign_videos_sample_a_6...\n",
              "2     0  /content/gdrive/MyDrive/sign_videos_sample_a_6...\n",
              "3     0  /content/gdrive/MyDrive/sign_videos_sample_a_6...\n",
              "4     0  /content/gdrive/MyDrive/sign_videos_sample_a_6..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b371a08-1517-41d1-9a86-12b18c5a25a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>/content/gdrive/MyDrive/sign_videos_sample_a_6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>/content/gdrive/MyDrive/sign_videos_sample_a_6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>/content/gdrive/MyDrive/sign_videos_sample_a_6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>/content/gdrive/MyDrive/sign_videos_sample_a_6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>/content/gdrive/MyDrive/sign_videos_sample_a_6...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b371a08-1517-41d1-9a86-12b18c5a25a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b371a08-1517-41d1-9a86-12b18c5a25a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b371a08-1517-41d1-9a86-12b18c5a25a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#creating the Matplotlib figure and specify the size of the figure\n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "with open(FOLDER_ROOT+'dataset.csv', 'w', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  for c in CLASSES_LIST:\n",
        "    path = os.path.join(DATASET_DIR, c+\"/\")\n",
        "    for i in os.listdir(path):\n",
        "      writer.writerow([CLASSES_LIST.index(c), os.path.join(path, i)])\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(FOLDER_ROOT+'dataset.csv', header=None)\n",
        "train_df.columns = [\"class\", \"path\"]\n",
        "train_df = train_df.astype({\"class\": str})\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0rLYO1shudM",
        "outputId": "640e55db-85ac-4b9b-eb19-76a8d7ddde51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', '1', '2', '3', '4', '5']\n"
          ]
        }
      ],
      "source": [
        "label_processor = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    num_oov_indices=0, vocabulary=np.unique(train_df[\"class\"])\n",
        ")\n",
        "print(label_processor.get_vocabulary())\n",
        "class_vocab = label_processor.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE2dg9xEfdIC"
      },
      "outputs": [],
      "source": [
        "def frames_extraction(video_path):\n",
        "\n",
        "  frames_list= []\n",
        "\n",
        "  video_reader = cv2.VideoCapture(video_path)\n",
        "\n",
        "  video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "  skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH),1)\n",
        "\n",
        "  for frame_counter in range(SEQUENCE_LENGTH):\n",
        "    video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "\n",
        "    success, frame = video_reader.read()\n",
        "\n",
        "    if not success:\n",
        "      break\n",
        "      \n",
        "    resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "\n",
        "    normalized_frame = resized_frame /255\n",
        "\n",
        "    frames_list.append(normalized_frame)\n",
        "\n",
        "  video_reader.release()\n",
        "  return frames_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyIrPDbrh7Zz"
      },
      "outputs": [],
      "source": [
        "def create_dataset():\n",
        "  features = []\n",
        "  labels = []\n",
        "  video_files_paths = []\n",
        "\n",
        "  for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "    print(f'Extracting Data of Class: {class_name}')\n",
        "\n",
        "    files_list = os.listdir(os.path.join(DATASET_DIR,class_name))\n",
        "\n",
        "    for file_name in files_list:\n",
        "      video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        "      frames = frames_extraction(video_file_path)\n",
        "\n",
        "      if len(frames) == SEQUENCE_LENGTH:\n",
        "        features.append(frames)\n",
        "        labels.append(class_index)\n",
        "        video_files_paths.append(video_file_path)\n",
        "        \n",
        "  features = np.asarray(features)\n",
        "  labels = np.array(labels)\n",
        "  return features, labels, video_files_paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiMYlhUyj6yO",
        "outputId": "d4cb5b2a-ed0e-4d17-8884-3d7fbb273f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data of Class: call_the_ambulance\n",
            "Extracting Data of Class: i_am_a_student\n",
            "Extracting Data of Class: i_can_not_speak\n",
            "Extracting Data of Class: how_are_you\n",
            "Extracting Data of Class: i_don't_understand\n",
            "Extracting Data of Class: extra_class\n"
          ]
        }
      ],
      "source": [
        "features, labels, video_files_paths = create_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv0SNHQpOMmW",
        "outputId": "0b7bd86f-7a2c-4a90-f5d9-5325dbbf86b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(451, 20, 224, 224, 3)\n",
            "(451,)\n"
          ]
        }
      ],
      "source": [
        "print(features.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2eL5RW4ktLC",
        "outputId": "8e78f7a6-0f85-49b2-86ce-a88c5f8af8b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(451, 6)\n"
          ]
        }
      ],
      "source": [
        "one_hot_encoded_labels = to_categorical(labels)\n",
        "print(one_hot_encoded_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHxu9NsalXgp"
      },
      "outputs": [],
      "source": [
        "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels,\n",
        "                                                                           test_size = 0.3, shuffle = True,\n",
        "                                                                           random_state = seed_constant)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l6qQaJux4Ld",
        "outputId": "7caea168-d91c-4c84-e475-35b7f65adc4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "407"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj7ayRQ7fFtu",
        "outputId": "547894a4-6a9d-44b7-fbbf-f0f9df47c6e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d (ConvLSTM2D)    (None, 20, 223, 223, 2)   168       \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 20, 111, 111, 2)  0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 20, 111, 111, 2)  0         \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " conv_lstm2d_1 (ConvLSTM2D)  (None, 20, 110, 110, 4)   400       \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPooling  (None, 20, 55, 55, 4)    0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 20, 55, 55, 4)    0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " conv_lstm2d_2 (ConvLSTM2D)  (None, 20, 53, 53, 16)    11584     \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPooling  (None, 20, 27, 27, 16)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 20, 27, 27, 16)   0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 233280)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 1399686   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,411,838\n",
            "Trainable params: 1,411,838\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model created successfully!\n"
          ]
        }
      ],
      "source": [
        "def create_convlstm_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(ConvLSTM2D(filters=2, kernel_size=(2,2), activation='relu', data_format=\"channels_last\",\n",
        "                     recurrent_dropout = 0.5, return_sequences =True, input_shape = (SEQUENCE_LENGTH,IMAGE_HEIGHT,IMAGE_WIDTH,3)))\n",
        "\n",
        "  model.add(MaxPooling3D(pool_size=(1,2,2), padding='valid', data_format='channels_last'))\n",
        "  model.add(TimeDistributed(Dropout(0.5)))\n",
        "\n",
        "  model.add(ConvLSTM2D(filters=4, kernel_size=(2,2), activation='relu', data_format=\"channels_last\",\n",
        "                     recurrent_dropout = 0.5, return_sequences =True))\n",
        "\n",
        "  model.add(MaxPooling3D(pool_size=(1,2,2),padding='valid', data_format='channels_last'))\n",
        "  model.add(TimeDistributed(Dropout(0.5)))\n",
        "\n",
        "  model.add(ConvLSTM2D(filters=16, kernel_size=(3,3), activation='tanh',data_format=\"channels_last\",\n",
        "                     recurrent_dropout = 0.4, return_sequences =True))\n",
        "\n",
        "  model.add(MaxPooling3D(pool_size=(1,2,2),padding='same', data_format='channels_last'))\n",
        "  model.add(TimeDistributed(Dropout(0.4)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(len(CLASSES_LIST), activation=\"softmax\"))\n",
        "\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "convlstm_model = create_convlstm_model()\n",
        "\n",
        "print(\"Model created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88RlTwBxfFwz"
      },
      "outputs": [],
      "source": [
        "# plot_model(convlstm_model, to_file='convlstm_model_structure_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZsN1WpycNlX",
        "outputId": "4d09339c-0ea5-4bf0-c5d5-11502667463d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features train:   (315, 20, 224, 224, 3)\n",
            "Labels train:  (315, 6)\n"
          ]
        }
      ],
      "source": [
        "print(\"Features train:  \", features_train.shape)\n",
        "print(\"Labels train: \", labels_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO10m7KUyklp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9bded8-f811-488d-c749-2a00dd02289f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        }
      ],
      "source": [
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, mode = 'min', restore_best_weights=True)\n",
        "# filepath = \"/tmp/video_classifier\"\n",
        "# checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "#     filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
        "#     )\n",
        "\n",
        "\n",
        "convlstm_model.compile(loss = 'categorical_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
        "\n",
        "convlstm_model_training_history = convlstm_model.fit(x=features_train, y = labels_train, epochs = 50, batch_size=32,\n",
        "                                                     validation_split=0.2,\n",
        "                                                     callbacks=[early_stopping_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPhyCrDgfEL4"
      },
      "outputs": [],
      "source": [
        "#convlstm_model.load_weights(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daFHCcsXPN-h"
      },
      "outputs": [],
      "source": [
        "history = convlstm_model_training_history\n",
        "\n",
        "print(\"Training accuracy: \", history.history['accuracy'][-1]*100)\n",
        "print(\"Training Loss: \", history.history['loss'][-1])\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"Validation accuracy: \", history.history['val_accuracy'][-1]*100)\n",
        "print(\"Validation Loss: \", history.history['val_loss'][-1])\n",
        "print(\"-----------------------------------------\\n\")\n",
        "\n",
        "accuracy = convlstm_model.evaluate(features_test, labels_test, verbose=0);\n",
        "print(f\"Test Accuracy: {round(accuracy[1] * 100, 2)}%\")\n",
        "print(f\"Test Loss: {round(accuracy[0], 2)}%\")\n",
        "\n",
        "\n",
        "# Plots\n",
        "plt.figure(1)\n",
        "\n",
        "# summarize history for accuracy\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "\n",
        "# summarize history for loss\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dOfpCyOQj6n"
      },
      "outputs": [],
      "source": [
        "convlstm_model.save(\"convlstm_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSxTQ8KvrSAD"
      },
      "outputs": [],
      "source": [
        "convlstm_model = keras.models.load_model('convlstm_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIl1EE9B4Y3a"
      },
      "source": [
        "### **Single Video Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udPjZxywmSnC"
      },
      "outputs": [],
      "source": [
        "from tensorflow_docs.vis import embed\n",
        "\n",
        "def load_video(video_path):\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  frames = []\n",
        "\n",
        "  video_reader = cv2.VideoCapture(video_path)\n",
        "\n",
        "  video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "  skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH),1)\n",
        "\n",
        "  try:\n",
        "    while True:\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "        break\n",
        "      frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "      frame = frame[:, :, [2, 1, 0]]\n",
        "      frames.append(frame)\n",
        "\n",
        "      if len(frames) == SEQUENCE_LENGTH:\n",
        "        break\n",
        "  finally:\n",
        "    cap.release()\n",
        "  return np.array(frames) / 255.0\n",
        "  \n",
        "\n",
        "def prepare_single_video(video_path):\n",
        "\n",
        "    single_video_features = []\n",
        "\n",
        "    frames = frames_extraction(video_path)\n",
        "    \n",
        "    if len(frames) == SEQUENCE_LENGTH:\n",
        "      single_video_features.append(frames)\n",
        "      \n",
        "    features = np.asarray(single_video_features)\n",
        "    \n",
        "    return features\n",
        "\n",
        "def sequence_prediction(video_path):\n",
        "  \n",
        "    class_vocab = label_processor.get_vocabulary() \n",
        "\n",
        "    frames = load_video(video_path)\n",
        "\n",
        "    frame_features = prepare_single_video(video_path)\n",
        "    probabilities = convlstm_model.predict(frame_features)\n",
        "\n",
        "    v = ['call_the_ambulance','i_am_a_student','i_can_not_speak', 'how_are_you', \"i_don't_understand\", 'extra_class'] # 5 a, 5 b\n",
        "\n",
        "    pred_class = v[np.argmax(probabilities)]\n",
        "    print(pred_class)\n",
        "    #for i in np.argsort(probabilities)[::-1]:  #Add [::-1][:no] for starting fix number samples\n",
        "     # print(f\"  {str(v[class_vocab[i].astype(int)])} :{class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
        "\n",
        "    frames_data = np.array(frames, dtype=np.float32)\n",
        "    return frames_data\n",
        "\n",
        "def to_gif(images):\n",
        "    converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
        "    imageio.mimsave('./animation.gif', converted_images, fps=30)\n",
        "    return embed.embed_file('./animation.gif')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DixOXJKkQOtz"
      },
      "outputs": [],
      "source": [
        "y_pred = convlstm_model.predict(features_test) \n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "Y_test = np.argmax(labels_test, axis=1)\n",
        "cm = confusion_matrix(Y_test, y_pred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5987rzPrQnxk"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score\n",
        "precision_score(Y_test,y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfwJgecaQsUA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision_recall_fscore_support(Y_test,y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CunH4i44iWY"
      },
      "source": [
        "### **Single Video Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP4gUt_vNG3h"
      },
      "outputs": [],
      "source": [
        "test_video = np.random.choice(train_df[\"path\"].values.tolist())  # Videos from train data. Note: We dont have test dataframe\n",
        "\n",
        "#test_video = '/content/sign_videos_sample_a_10/how_are_you/how_are_you-11.mp4'\n",
        "print(f\"Test video path: {test_video}\")\n",
        "test_frames = sequence_prediction(test_video)\n",
        "\n",
        "#to_gif(test_frames[:SEQUENCE_LENGTH])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "FYP_ConvLSTM_Updated_May_23.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}